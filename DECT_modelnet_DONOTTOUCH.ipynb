{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(y=[1], x=[100, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8765)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from models.layers.layers import EctLayer\n",
    "from models.config import EctConfig\n",
    "\n",
    "from torch_geometric.data import Batch, Data\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt \n",
    "from datasets.modelnet import ModelNetDataModule\n",
    "from datasets.config import ModelNetDataModuleConfig\n",
    "\n",
    "dataset = ModelNetDataModule(ModelNetDataModuleConfig(root=\"./data/modelnet_40_100\",samplepoints=100))\n",
    "print(dataset.entire_ds[0])\n",
    "ECT_SIZE = 128\n",
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "data = dataset.entire_ds[0]\n",
    "data.x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = EctLayer(config = EctConfig(num_thetas=ECT_SIZE,bump_steps=ECT_SIZE,num_features=3,device=DEVICE))\n",
    "\n",
    "        # encoder_layer = nn.TransformerEncoderLayer(\n",
    "        #     d_model=64,\n",
    "        #     nhead=4,\n",
    "        #     dim_feedforward=256,\n",
    "        #     dropout=0.0,\n",
    "        # )\n",
    "        # self.transformer_encoder = nn.TransformerEncoder(\n",
    "        #     encoder_layer,\n",
    "        #     num_layers=6,\n",
    "        # )\n",
    "        \n",
    "        HIDDEN = 128\n",
    "\n",
    "        self.classifiers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(ECT_SIZE**2,HIDDEN), # (N, 784) -> (N, 128)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN, HIDDEN),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN, 40) \n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = self.layer(batch)\n",
    "        # x = self.transformer_encoder(x)\n",
    "        # x = x.mean(dim=1)\n",
    "        x = self.classifiers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 40])\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder().to(DEVICE)\n",
    "\n",
    "\n",
    "for batch in dataset.train_dataloader():\n",
    "    batch = batch.to(DEVICE)\n",
    "    # img = img.reshape(-1, 28*28) # -> use for Autoencoder_Linear\n",
    "\n",
    "res = model(batch)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(model, loader, num_classes=None):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.eval()\n",
    "    acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "    # auroc = AUROC(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    loss = torch.tensor([0.0], device=device)\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch_gpu, y_gpu = batch.to(device), batch.y.to(device)\n",
    "            logits = model(batch_gpu)\n",
    "            loss += loss_fn(logits, y_gpu)\n",
    "            # auroc(logits, y_gpu)\n",
    "            acc(logits, y_gpu)\n",
    "    a = acc.compute()\n",
    "    # roc = auroc.compute()\n",
    "    acc.reset()\n",
    "    # auroc.reset()\n",
    "    return loss, a, torch.tensor([0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder().to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:4.0066, Acc:0.0396\n",
      "Epoch:2, Loss:3.2945, Acc:0.0528\n",
      "Epoch:3, Loss:3.4037, Acc:0.0599\n",
      "Epoch:4, Loss:3.2990, Acc:0.0716\n",
      "Epoch:5, Loss:3.3504, Acc:0.1112\n",
      "Epoch:6, Loss:3.1743, Acc:0.1290\n",
      "Epoch:7, Loss:3.3127, Acc:0.1346\n",
      "Epoch:8, Loss:3.7926, Acc:0.1712\n",
      "Epoch:9, Loss:2.7485, Acc:0.2031\n",
      "Epoch:10, Loss:2.7308, Acc:0.2732\n",
      "Epoch:11, Loss:2.6822, Acc:0.2936\n",
      "Epoch:12, Loss:2.7383, Acc:0.2646\n",
      "Epoch:13, Loss:2.4175, Acc:0.3149\n",
      "Epoch:14, Loss:2.8897, Acc:0.2753\n",
      "Epoch:15, Loss:2.9012, Acc:0.3261\n",
      "Epoch:16, Loss:2.2556, Acc:0.2854\n",
      "Epoch:17, Loss:1.0269, Acc:0.3738\n",
      "Epoch:18, Loss:2.3719, Acc:0.3266\n",
      "Epoch:19, Loss:1.6876, Acc:0.3443\n",
      "Epoch:20, Loss:2.3703, Acc:0.4053\n",
      "Epoch:21, Loss:3.2744, Acc:0.3956\n",
      "Epoch:22, Loss:1.1847, Acc:0.4099\n",
      "Epoch:23, Loss:1.4998, Acc:0.4266\n",
      "Epoch:24, Loss:1.9759, Acc:0.3677\n",
      "Epoch:25, Loss:6.4440, Acc:0.3337\n",
      "Epoch:26, Loss:3.8111, Acc:0.4033\n",
      "Epoch:27, Loss:2.9135, Acc:0.3804\n",
      "Epoch:28, Loss:2.1379, Acc:0.4342\n",
      "Epoch:29, Loss:1.3414, Acc:0.4231\n",
      "Epoch:30, Loss:4.0613, Acc:0.4027\n",
      "Epoch:31, Loss:3.2484, Acc:0.3895\n",
      "Epoch:32, Loss:1.4198, Acc:0.4505\n",
      "Epoch:33, Loss:2.7957, Acc:0.4525\n",
      "Epoch:34, Loss:2.1102, Acc:0.4302\n",
      "Epoch:35, Loss:1.0885, Acc:0.4444\n",
      "Epoch:36, Loss:2.2692, Acc:0.4180\n",
      "Epoch:37, Loss:1.2779, Acc:0.4363\n",
      "Epoch:38, Loss:1.3331, Acc:0.4860\n",
      "Epoch:39, Loss:2.2896, Acc:0.4368\n",
      "Epoch:40, Loss:2.9909, Acc:0.4799\n",
      "Epoch:41, Loss:2.5809, Acc:0.4799\n",
      "Epoch:42, Loss:2.8349, Acc:0.4830\n",
      "Epoch:43, Loss:1.6823, Acc:0.4754\n",
      "Epoch:44, Loss:2.1388, Acc:0.4810\n",
      "Epoch:45, Loss:0.4060, Acc:0.4804\n",
      "Epoch:46, Loss:2.9836, Acc:0.4728\n",
      "Epoch:47, Loss:1.0393, Acc:0.4850\n",
      "Epoch:48, Loss:1.5246, Acc:0.4876\n",
      "Epoch:49, Loss:2.3165, Acc:0.4850\n",
      "Epoch:50, Loss:2.3323, Acc:0.4759\n",
      "Epoch:51, Loss:1.2718, Acc:0.4921\n",
      "Epoch:52, Loss:2.2104, Acc:0.4896\n",
      "Epoch:53, Loss:1.1100, Acc:0.5155\n",
      "Epoch:54, Loss:1.1639, Acc:0.5150\n",
      "Epoch:55, Loss:1.2128, Acc:0.4957\n",
      "Epoch:56, Loss:1.4619, Acc:0.4957\n",
      "Epoch:57, Loss:0.8314, Acc:0.4982\n",
      "Epoch:58, Loss:2.3554, Acc:0.5170\n",
      "Epoch:59, Loss:1.4106, Acc:0.4967\n",
      "Epoch:60, Loss:1.0649, Acc:0.4926\n",
      "Epoch:61, Loss:0.7429, Acc:0.5368\n",
      "Epoch:62, Loss:1.9389, Acc:0.4860\n",
      "Epoch:63, Loss:1.7933, Acc:0.5119\n",
      "Epoch:64, Loss:2.0642, Acc:0.4774\n",
      "Epoch:65, Loss:1.9396, Acc:0.4713\n",
      "Epoch:66, Loss:2.7026, Acc:0.5262\n",
      "Epoch:67, Loss:0.3440, Acc:0.5196\n",
      "Epoch:68, Loss:1.2808, Acc:0.5074\n",
      "Epoch:69, Loss:3.1778, Acc:0.5444\n",
      "Epoch:70, Loss:0.6559, Acc:0.5236\n",
      "Epoch:71, Loss:2.7327, Acc:0.5190\n",
      "Epoch:72, Loss:4.9064, Acc:0.5008\n",
      "Epoch:73, Loss:2.3137, Acc:0.5104\n",
      "Epoch:74, Loss:1.7540, Acc:0.5404\n",
      "Epoch:75, Loss:0.4982, Acc:0.5272\n",
      "Epoch:76, Loss:2.0179, Acc:0.5196\n",
      "Epoch:77, Loss:0.3545, Acc:0.5419\n",
      "Epoch:78, Loss:1.3585, Acc:0.5343\n",
      "Epoch:79, Loss:3.2113, Acc:0.5185\n",
      "Epoch:80, Loss:2.6799, Acc:0.5368\n",
      "Epoch:81, Loss:2.4335, Acc:0.5201\n",
      "Epoch:82, Loss:0.6918, Acc:0.5241\n",
      "Epoch:83, Loss:1.8588, Acc:0.4815\n",
      "Epoch:84, Loss:3.2322, Acc:0.5429\n",
      "Epoch:85, Loss:3.2047, Acc:0.5236\n",
      "Epoch:86, Loss:1.6977, Acc:0.5490\n",
      "Epoch:87, Loss:0.6175, Acc:0.5394\n",
      "Epoch:88, Loss:1.4825, Acc:0.5434\n",
      "Epoch:89, Loss:0.4361, Acc:0.5434\n",
      "Epoch:90, Loss:0.9082, Acc:0.5434\n",
      "Epoch:91, Loss:2.4359, Acc:0.5444\n",
      "Epoch:92, Loss:2.5298, Acc:0.5500\n",
      "Epoch:93, Loss:1.2211, Acc:0.5272\n",
      "Epoch:94, Loss:4.4178, Acc:0.5241\n",
      "Epoch:95, Loss:1.6069, Acc:0.5292\n",
      "Epoch:96, Loss:1.8001, Acc:0.5658\n",
      "Epoch:97, Loss:0.6743, Acc:0.5582\n",
      "Epoch:98, Loss:1.0727, Acc:0.5460\n",
      "Epoch:99, Loss:0.8781, Acc:0.5602\n",
      "Epoch:100, Loss:1.1734, Acc:0.5251\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for batch in dataset.train_dataloader():\n",
    "        batch_gpu, y_gpu = batch.to(DEVICE), batch.y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch_gpu)\n",
    "        loss = loss_fn(pred, y_gpu)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # raise \"hello\"\n",
    "\n",
    "    val_loss, acc, _ = compute_acc(model, dataset.val_dataloader(), 40)\n",
    "\n",
    "    # del batch_gpu, y_gpu, pred, loss\n",
    "    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}, Acc:{acc.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5028, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "val_loss, acc, _ = compute_acc(model, dataset.test_dataloader(), 40)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
